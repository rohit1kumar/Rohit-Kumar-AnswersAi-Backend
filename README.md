# AnswersAi

### Tech Stack
- Node.js
- Express.js
- Postgres
- Sequelize ORM
- Docker

### How to setup and run the project
1. Clone the repo & update the `.env` file

   ```bash
   git clone https://github.com/rohit1kumar/Rohit-Kumar-AnswersAi-Backend.git
   cd Rohit-Kumar-AnswersAi-Backend
   cp .env.example .env
   ```

2. (Optional) Use Docker:

   ```bash
   docker-compose up --build
   ```

3. (if not using Docker) Install dependencies & run:

   ```bash
   npm install
   npm run dev
   ```

4. The server should be running on `http://localhost:8000`
5. Test health check:

   ```bash
   curl http://localhost:8000/healthz
   ```
### API Documentation
Import the Postman Collection from [docs](./docs/postman_collection.json)

### Database Schema
![Database Schema](./docs/erd_diagram.jpg)

### Infra Diagram
![Infra Diagram](./docs/infra.jpg)
*note: Generated by Claude*

### Misc Answers
Q: Please document a solution that ensures that users get timely responses even during periods of high load.

A: Without knowing the bottleneck, it's hard to suggest a solution. But, here are some general suggestions:
- Use a load balancer to distribute the load across multiple servers.
- Indexing the database to speed up the queries.
- Use database read replicas for spreading load
- Set up auto-scaling for servers based on traffic
- Use a caching mechanism to cache the frequently accessed data.
- Asynchronous processing using message queue with seperate worker for ai response generation, with support for polling the status for answer.
- Caching similar questions and their responses to reduce the load on the AI worker
